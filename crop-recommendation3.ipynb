{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f812497-6f84-4d33-9563-9682be2c93b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings \n",
    "  \n",
    "print('Hello') \n",
    "  \n",
    "# Settings the warnings to be ignored \n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7da157-d884-43c8-943e-7bbc43d57f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Crop_recommendation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ad0a4-1133-4e4e-8502-51723ca712c3",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4eba85a-5d8d-4901-bc90-02a7266e79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2a1f27-5a4a-423b-a4c9-83f503185ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns='label'),\n",
    "    df['label'],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3bb2fa-f4f8-4a66-9996-fa7266804062",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_test.npy', x_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478eff3-2367-4d96-af27-a167b7970c4f",
   "metadata": {},
   "source": [
    "# column Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d4d5fe5-a171-4508-af9a-79fdc98c3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764d6d07-9ac3-4865-969e-c95e1f08b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf1 = ColumnTransformer(transformers=[\n",
    "    ('standarisation', StandardScaler(with_mean=False), [0,6]),\n",
    "],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0165ce-9f89-4d5a-ba32-37a03501b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf2 = ColumnTransformer(transformers=[\n",
    "    ('ohe_label', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), [-1])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83824dc4-590a-41d1-b8e6-7bcc82f2b3c7",
   "metadata": {},
   "source": [
    "# importing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5c5050-d436-4140-aa0b-b575ebe4f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  # k-Nearest Neighbors (KNN)\n",
    "from sklearn.svm import SVC  # Support Vector Machine (SVM)\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree Classifier\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression\n",
    "from sklearn.naive_bayes import GaussianNB  # Naive Bayes\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # Gradient Boosting Machine (GBM)\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3dc07a-34d8-4d6e-ac42-96a1d86bce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e21902d-87ee-40b1-ae44-834b501a9e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'LogisticRegression', 'GaussianNB', 'GradientBoostingClassifier', 'RandomForestClassifier'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1216f6-58b4-4709-bb9c-8132f6a55f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier pipeline: Pipeline(steps=[('scaler',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('standarisation',\n",
      "                                                  StandardScaler(with_mean=False),\n",
      "                                                  [0, 6])])),\n",
      "                ('model', KNeighborsClassifier())])\n",
      "SVC pipeline: Pipeline(steps=[('scaler',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('standarisation',\n",
      "                                                  StandardScaler(with_mean=False),\n",
      "                                                  [0, 6])])),\n",
      "                ('model', SVC())])\n",
      "DecisionTreeClassifier pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                sparse_output=False),\n",
      "                                                  [-1])])),\n",
      "                ('model', DecisionTreeClassifier())])\n",
      "LogisticRegression pipeline: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                sparse_output=False),\n",
      "                                                  [-1])])),\n",
      "                ('model', LogisticRegression())])\n",
      "GaussianNB pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                sparse_output=False),\n",
      "                                                  [-1])])),\n",
      "                ('model', GaussianNB())])\n",
      "GradientBoostingClassifier pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                sparse_output=False),\n",
      "                                                  [-1])])),\n",
      "                ('model', GradientBoostingClassifier())])\n",
      "RandomForestClassifier pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                sparse_output=False),\n",
      "                                                  [-1])])),\n",
      "                ('model', RandomForestClassifier())])\n"
     ]
    }
   ],
   "source": [
    "pipelines = {\n",
    "    'KNeighborsClassifier': Pipeline([\n",
    "        ('scaler', trf1) , # StandardScaler as a preprocessing step\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('scaler', trf1),\n",
    "        ('model', SVC())\n",
    "    ]),\n",
    "    'DecisionTreeClassifier': Pipeline([\n",
    "        # No need to scale for Decision Tree, so skipping the scaler\n",
    "        ('encode', trf2),\n",
    "        ('model', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('encode', trf2),\n",
    "        ('model', LogisticRegression())\n",
    "    ]),\n",
    "    'GaussianNB': Pipeline([\n",
    "        # Naive Bayes does not require scaling, skipping the scaler\n",
    "        ('encode', trf2),\n",
    "        ('model', GaussianNB())\n",
    "    ]),\n",
    "    'GradientBoostingClassifier': Pipeline([\n",
    "        # Skipping scaler for GBM as it doesn't need feature scaling\n",
    "        ('encode', trf2),\n",
    "        ('model', GradientBoostingClassifier())\n",
    "    ]),\n",
    "    'RandomForestClassifier': Pipeline([\n",
    "        # Skipping scaler for Random Forest as it's not necessary\n",
    "        ('encode', trf2),\n",
    "        ('model', RandomForestClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Optionally, print the pipelines to check\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f\"{model_name} pipeline:\", pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68a1d0af-f41b-47b2-b235-e7f3a1946ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier mode with accuracy: 0.9136363636363637\n",
      "SVC mode with accuracy: 0.8772727272727273\n",
      "DecisionTreeClassifier mode with accuracy: 0.9431818181818182\n",
      "LogisticRegression mode with accuracy: 0.9159090909090909\n",
      "GaussianNB mode with accuracy: 0.5613636363636364\n",
      "GradientBoostingClassifier mode with accuracy: 0.9545454545454546\n",
      "RandomForestClassifier mode with accuracy: 0.9727272727272728\n"
     ]
    }
   ],
   "source": [
    "for name, model in pipelines.items():\n",
    "    model.fit(x_train.values, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} mode with accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4535bda-5d52-427f-a120-7779784e5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "\"KNeighborsClassifier\" : \"models/KNeighborsClassifier.pkl\",\n",
      "\"SVC\" : \"models/SVC.pkl\",\n",
      "\"DecisionTreeClassifier\" : \"models/DecisionTreeClassifier.pkl\",\n",
      "\"LogisticRegression\" : \"models/LogisticRegression.pkl\",\n",
      "\"GaussianNB\" : \"models/GaussianNB.pkl\",\n",
      "\"GradientBoostingClassifier\" : \"models/GradientBoostingClassifier.pkl\",\n",
      "\"RandomForestClassifier\" : \"models/RandomForestClassifier.pkl\",\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print(\"Hello\")\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f'\"{model_name}\" : \"models/{model_name}.pkl\",')\n",
    "    file = pickle.dump(pipeline, open(f'models/{model_name}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba937a-2d36-44f3-a610-372ad5118ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
