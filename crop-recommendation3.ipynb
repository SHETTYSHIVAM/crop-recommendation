{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f812497-6f84-4d33-9563-9682be2c93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7da157-d884-43c8-943e-7bbc43d57f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Crop_recommendation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ad0a4-1133-4e4e-8502-51723ca712c3",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4eba85a-5d8d-4901-bc90-02a7266e79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f2a1f27-5a4a-423b-a4c9-83f503185ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns='label'),\n",
    "    df['label'],\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478eff3-2367-4d96-af27-a167b7970c4f",
   "metadata": {},
   "source": [
    "# column Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d4d5fe5-a171-4508-af9a-79fdc98c3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "764d6d07-9ac3-4865-969e-c95e1f08b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf1 = ColumnTransformer(transformers=[\n",
    "    ('standarisation', StandardScaler(with_mean=False), [0,6]),\n",
    "],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0165ce-9f89-4d5a-ba32-37a03501b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf2 = ColumnTransformer(transformers=[\n",
    "    ('ohe_label', OneHotEncoder(sparse=False, handle_unknown='ignore'), [-1])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83824dc4-590a-41d1-b8e6-7bcc82f2b3c7",
   "metadata": {},
   "source": [
    "# importing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce5c5050-d436-4140-aa0b-b575ebe4f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  # k-Nearest Neighbors (KNN)\n",
    "from sklearn.svm import SVC  # Support Vector Machine (SVM)\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree Classifier\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression\n",
    "from sklearn.naive_bayes import GaussianNB  # Naive Bayes\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # Gradient Boosting Machine (GBM)\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f3dc07a-34d8-4d6e-ac42-96a1d86bce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e21902d-87ee-40b1-ae44-834b501a9e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'LogisticRegression', 'GaussianNB', 'GradientBoostingClassifier', 'RandomForestClassifier'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c1216f6-58b4-4709-bb9c-8132f6a55f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier pipeline: Pipeline(steps=[('scaler',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('standarisation',\n",
      "                                                  StandardScaler(with_mean=False),\n",
      "                                                  [0, 6])])),\n",
      "                ('model', KNeighborsClassifier())])\n",
      "SVC pipeline: Pipeline(steps=[('scaler',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('standarisation',\n",
      "                                                  StandardScaler(with_mean=False),\n",
      "                                                  [0, 6])])),\n",
      "                ('model', SVC())])\n",
      "DecisionTreeClassifier pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [-1])])),\n",
      "                ('model', DecisionTreeClassifier())])\n",
      "LogisticRegression pipeline: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [-1])])),\n",
      "                ('model', LogisticRegression())])\n",
      "GaussianNB pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [-1])])),\n",
      "                ('model', GaussianNB())])\n",
      "GradientBoostingClassifier pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [-1])])),\n",
      "                ('model', GradientBoostingClassifier())])\n",
      "RandomForestClassifier pipeline: Pipeline(steps=[('encode',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe_label',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  [-1])])),\n",
      "                ('model', RandomForestClassifier())])\n"
     ]
    }
   ],
   "source": [
    "pipelines = {\n",
    "    'KNeighborsClassifier': Pipeline([\n",
    "        ('scaler', trf1) , # StandardScaler as a preprocessing step\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('scaler', trf1),\n",
    "        ('model', SVC())\n",
    "    ]),\n",
    "    'DecisionTreeClassifier': Pipeline([\n",
    "        # No need to scale for Decision Tree, so skipping the scaler\n",
    "        ('encode', trf2),\n",
    "        ('model', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('encode', trf2),\n",
    "        ('model', LogisticRegression())\n",
    "    ]),\n",
    "    'GaussianNB': Pipeline([\n",
    "        # Naive Bayes does not require scaling, skipping the scaler\n",
    "        ('encode', trf2),\n",
    "        ('model', GaussianNB())\n",
    "    ]),\n",
    "    'GradientBoostingClassifier': Pipeline([\n",
    "        # Skipping scaler for GBM as it doesn't need feature scaling\n",
    "        ('encode', trf2),\n",
    "        ('model', GradientBoostingClassifier())\n",
    "    ]),\n",
    "    'RandomForestClassifier': Pipeline([\n",
    "        # Skipping scaler for Random Forest as it's not necessary\n",
    "        ('encode', trf2),\n",
    "        ('model', RandomForestClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Optionally, print the pipelines to check\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f\"{model_name} pipeline:\", pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68a1d0af-f41b-47b2-b235-e7f3a1946ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier mode with accuracy: 0.9272727272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC mode with accuracy: 0.8681818181818182\n",
      "DecisionTreeClassifier mode with accuracy: 0.9727272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression mode with accuracy: 0.9\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m pipelines\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(x_train\u001b[38;5;241m.\u001b[39mvalues, y_train)\n\u001b[0;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      4\u001b[0m     score \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_fit(\n\u001b[0;32m    264\u001b[0m     X, y, np\u001b[38;5;241m.\u001b[39munique(y), _refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[0;32m    265\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:423\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    422\u001b[0m first_call \u001b[38;5;241m=\u001b[39m _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[1;32m--> 423\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39mfirst_call)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:883\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    882\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 883\u001b[0m     array \u001b[38;5;241m=\u001b[39m _ensure_sparse_format(\n\u001b[0;32m    884\u001b[0m         array,\n\u001b[0;32m    885\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    886\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    887\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    888\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    889\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m    890\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    891\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    892\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:534\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    531\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sparse matrix was passed, but dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is required. Use X.toarray() to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m     )\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "for name, model in pipelines.items():\n",
    "    model.fit(x_train.values, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} mode with accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4535bda-5d52-427f-a120-7779784e5abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
